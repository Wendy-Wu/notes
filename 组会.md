# 组会记录

记录组会时间、主讲人、内容、问题、讨论、启示、后续跟进等。

## 2024.8.12 SLAM 

- 主讲人：丁磊

- 内容：

  - 背景：

    - ICRA论文ONek-SLAM 
    - 基于神经辐射场、关键点
    - 基于Nerf，提高密集SLAM的重建精度
    - 大多缺乏细粒度细节，且对光照变化敏感
    - SIFT在光变条件下具有鲁棒性
    - 因此，本文联合特征点和对象级的Nerf，构建SLAM系统

  - 论文方法：

    - 输入RGB图像和跨帧对象级掩码

    - 对象级位姿估计：用SIFT从图像中提取特征点，并对用对象掩码定位到特征点属于哪个对象，*计算重投影误差？*优化位姿，位姿估计得到轨迹，初始帧和后续运动帧的特征点匹配，匹配到同一个物体，得到旋转平移变化矩阵，从而算出轨迹。

    - 对象级Nerf优化：将场景分割，每个对象由边界框和掩码定义，对每个对象选取像素点，使用NeRF模型预测其在世界坐标系中的颜色和占有率，并计算损失函数。

    - 自适应场景管理：提高鲁棒性

      - **==通过计算重投影误差和光度/深度损失函数，识别和排除动态物体==**

      - 加入一个参数$ \lambda $ 调节权重

        *怎么识别光照条件不好？黑夜、颠簸*（可能有规律模型）
    
  - 实验结果

    - DataSet: Replica, ScanNet, TUM RGB-D
  - *评价指标？* 针对3D重建和对象级识别方面，有哪些特殊的评价指标
  
- 提问：
    - 加激光雷达数据会不会更好抵御光照影响？将深度图像信息换成激光雷达点云去做
  - 为什么想讲这篇论文？
    - 离线训练的还是在线训练的？边训练边预测？
    - NeRF的作用是什么？
  - 如果RGB色彩分布，很丰富，特征点很多，那如何进行NeRF？特征点多，匹配可能越好