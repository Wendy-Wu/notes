2025.3.1 组会，下次是周六1点、周三是汇报进展

# 1 巩炜晟 

- 现场使用deepseek, 询问改进r3live SLAM的松/紧耦合办法、可行性

- 拓展适应不同天气、光照的场景
- 现场做PPT（将deepseek的大纲导入咪鼠AI）
- 《R3LIVE赋能：多传感器融合SLAM新突破》

问题：

- 怎么让deepseek深度思考那么多次？
- 输入的大纲是什么？
- 通过图片的光照调整权重参数还是比较合理
- 代码全部输出了吗？
- 试试看豆包能做吗？
- 配环境呢？
- 有没有参考源追溯？
- cursor可以给出整个项目代码
- AI题词师
- 如何拥抱AI，以后人可以做什么？
- 可以用AI想科研课题吗？大的方向可能还是人去做
- 有没有冗余的传感器
- deepseek的问题：
  - 多传感器频率不同导致时间同步问题
  - 误差累积
  - 动态物体
  - 计算资源瓶颈

- 非视距SLAM的项目理解：信号可以穿墙过去，穿墙感知环境

- SLAM和电磁地图正好是个逆过程

  

# 2 王钰焮

- 《Towards Robust 3D Object Detection with LiDAR and 4D Radar Fusion in Various Weather Conditions》
- CVPR 2024
- 静态融合策略无法适配动态环境变化
  - 通过WRGNet门控动态调整

问题：

- 能否做一个语义SLAM，通过融合目标检测和SLAM
- 4D毫米波雷达的型号是什么
- 融合策略是什么
- 3D目标检测出的是什么？
  - 类别
  - 几何形状、姿态
- 数据库是只用来做目标检测的数据库？
- 单一传感器的局限
- 核心创新点
- 针对方法概述的提问：
  - 1. 输入和输出分别是什么
    2. 输出为什么是鸟瞰图？（可能是自动驾驶这个领域对高度信息不敏感。默认所有车在一个平面上）有没有输出点云上的框
    3. 对不同模态的三个输入分别做了什么处理
    4. 为什么取半径为R的体素
    5. 白色的点后续是剔除了还是？
    6. 3D激光雷达的点云和4D毫米波点云是怎么对齐的？（K-Radar数据集里已经对齐了、可能是可视化后手动对齐）
    7. 虚线和实线是什么？
    8. 4D雷达颜色代表的是什么？（反射率，可能是张量）
    9. 下次还讲这篇
- 用AI读文章时，注意辨别