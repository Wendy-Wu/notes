# 智能导盲项目代码解读

## 1.代码目录结构

- CDNet-yolov5-main

  - data
  - datablind
  - datacrosswalk
  - datalight
  - images
  - models
  - runs
  - test
  - tools
  - utils
  - venv
  - weights
  - 以及一些同级的代码文件：
    - change.py
    - class.txt
    - coco.py
    - detect.py
    - export.py
    - FPS.py
    - get_COCO_metrice.py
    - gracam.py
    - hubconf.py
    - jsontotxt.py
    - plotact.py
    - requirements.txt
    - README.md
    - target.json
    - testyolo.py
    - train.py
    - val.py
  - data_process
  - labelimg-master-master

- smart_eye

  - demo

  - models

    - 存放转好格式为blob的训练权重文件

  - others

    - 别人工程里的一些图片文件

  - 以及其他一些代码文件

    - depthai_utils.py

      - Contains the code for each of the Pipeline required in this project

        The **Pipelines** involved are:

        ##### Navigation

        - obstacle detection
        - obstacle avoidance
        - social distancing

        ##### Walkable road path segmentation

        - road path segmentation for pedestrian's perspective

        ##### Pedestrian traffic light detection

        - to detect and classify the traffic light for pedestrian

        ##### Protective Equipment (PPE) detection

        - to detect hand sanitizer/face mask/thermometer
  
    - draw.py
  
      - 画标注框，helloworld级别
  
    - gps.py
  
      - the demo code for our gps system
      - it is seperated out from the main.py because it is hardware-dependant code
  
    - main.py
  
      - 主线程
      - 流程参考了别人的工作：
        - ![program flowchart](https://raw.githubusercontent.com/Wendy-Wu/imagebed/main/img/program flowchart.png)
  
    - oak_blind.py
  
      - 识别车道线（斑马线为负样本？)，跑的是crosswalkPipeline.run()
  
    - oakd_all.py
  
      - 识别全类别，但跑的是crosswalkPipeline.run()
  
    - oakd_crosswalk.py
  
      - 识别斑马线（车道线是负样本？），跑的是crosswalkPipeline.run()
  
    - oakd_navigation.py
  
      - 别人的工作，label包括了很多实体目标，比如车，鸟，人。跑的是navPipeline.run()
  
    - oakd_ppes.py
  
      - 别人的工作，检测ppe，利用语音输入指令。

        ```python
        speech = SpeechRecognizer()
        speech.start()
        ```
  
      - 跑的是如下pipeline：
  
      - ```python
        ppesPipeline.run(speech)
        speech.listen = False
        speech.end = True     
        speech.join()  
        ```

    - oakd_ppes_no_audio.py

      - 别人的工作，没有语音输入的情况。

    - oakd_segmentation.py
  
      - 别人的语义分割道路的工作
  
    - oakd_traffic_light.py
  
      - 红绿灯识别的线程。
  
    - OUTPUT.py
  
      - 输出目标框
      - 设置视频流路径、模型路径
      - 创建pipeline
      - 设置模型、yolo参数比如类别数目、IoU阈值、anchor初始位置
      - 连接到设备并启动Pipeline
      - 发送帧到设备
      - 从设备获取检测结果
      - 显示和保存处理后的帧
  
    - README.md
  
      - 别人工作里的工程说明文件。
  
        OpenCV-AI-Competition-UTAR4Vision
  
        We are team **UTAR4Vision**!
        This is the github repository for our team project - **Visually Impaired Assistance in COVID-19 Pandemic Outbreak**.
  
      - 有关oak-d，pipeline的说明
  
      - 对每个oak_...py的文件介绍
  
    - speaktest.py
  
      - 测试语音功能
  
    - task_utils.py
  
      - ##### Speech Recognition
  
        - an OOP object for speech recognition and voice command
        - designed for multithreading
  
      - ##### Navigator
  
        - contains the functions for obstacle avoidance, social distancing
  
    - test.py
  
      - 测试创建pipeline，连接设备、运行pipeline
  
    - testAll.py
  
      - 测试全类别检测
      - 代码构建与OUTPUT.py相似
  
    - testvedio.py
  
      - main函数路径包括了输入是视频流还是摄像头这两种选择
      - 根据输入，具体创建pipeline
      - 根据视频流，创建model neural network
      - 并且运行pipeline和网络，检测目标
  
    - v5_oakd_traffic_light.py
  
      - 别人工作里的红绿灯检测
  
    - vedio.py
  
      - 视频的读取显示，helloworld级别
  
    - yolov4_crosswalk.py
  
      - 别人工作里的斑马线检测
  
    - yolov8_oak.py
  
      - 暂时没看出来是v8