# 智能导盲项目代码解读

## 1.代码目录结构

- CDNet-yolov5-main

  - data

  - datablind

  - datacrosswalk

  - datalight

  - images

  - models

  - runs

  - test

  - tools

  - utils

    - autoanchor.py

      - 自动生成初始锚框，利用kmeans

    - autobatch.py

      - 根据CUDA自动估计出最佳的batch size

    - benchmarks.py

      - ##### 一行命令测试你的模型怎么跑更快

      - ```
        python utils/benchmarks.py --weights yolov5s.pt --img 640
        ```

    - callbacks.py

      - 回调函数的注册

    - datasets.py

      - 加载数据
      - 创建文件夹
      - 自动分割训练集、测试集、验证集
      - 等等

    - downloads.py

      - 下载器

    - general.py

      - 各种没单独分出去的小工具都集合在这里了
      - 比如：判断环境、文件大小、检查git status、检查系统是否支持图片等

    - loss.py

      - 损失函数的计算

    - metrics.py

      - IoU的计算
      - AP的计算
      - 混淆矩阵的计算

    - plots.py

      - 绘制工具

    - torch_utils.py

      - pytorch的一些使用接口，如：提供*Profiler*来分析神经网络性能

  - weights

    - 放了3个权重文件

  - 以及一些同级的代码文件：
    - change.py

      - helloworld级别，创建模型
      - 评估模型，输出指标

    - class.txt

      - 5个类别信息：

      - ```
        1 blind_path
        2 green_light
        3 block
        4 no_light
        5 red_light
        ```

    - coco.py

      - 将数据转为coco数据集的格式

    - detect.py

      - 做实际预测，用法是：

      - ```
         python path/to/detect.py --weights yolov5s.pt
        ```

    - export.py

      - yolov5官方代码，把yolo模型导出成其他格式

    - FPS.py

      - 计算FPS

    - get_COCO_metrice.py

      - 得到coco数据集上的评估指标

    - gracam.py

      - Grad-CAM热力图分析

    - hubconf.py

      - yolov5系列模型创建的集成器

    - jsontotxt.py

      -  COCO 格式的数据集转化为 YOLO 格式的数据集

    - plotact.py

      - pyplot绘画

    - requirements.txt

      - 安装依赖

    - README.md

      - 《CDNet: 一个基于YOLOv5的在Jetson Nano(英伟达边缘计算设备)上实时、鲁棒的斑马线检测网络》
        1. *实现了斑马线检测和车辆过线行为检测。*
        2. *在特定任务中准确率和速度超过原生YOLOv5。*
        3. *在阴天、晴天、雨天、夜间等真实复杂场景中实现高鲁棒性。*
        4. *在 Jetson nano 边缘计算设备上实现实时检测 (33.1 FPS)。*
        5. *提供了标注好的斑马线数据集，共计6868张图 。*

    - target.json

      - 过程文件，里面有各种键值对、标签

    - testyolo.py

      - 测试接入yolo
      - 创建model
      - 运行model.train()

    - train.py

      - yolov5的训练代码

    - val.py

      - yolov5的验证代码，在用户自定义数据集上给出模型预测的准确度等指标

- data_process

- labelimg-master-master

- smart_eye

  - demo

  - models

    - 存放转好格式为blob的训练权重文件

  - others

    - 别人工程里的一些图片文件

  - 以及其他一些代码文件

    - depthai_utils.py

      - Contains the code for each of the Pipeline required in this project

        The **Pipelines** involved are:

        ##### Navigation

        - obstacle detection
        - obstacle avoidance
        - social distancing

        ##### Walkable road path segmentation

        - road path segmentation for pedestrian's perspective

        ##### Pedestrian traffic light detection

        - to detect and classify the traffic light for pedestrian

        ##### Protective Equipment (PPE) detection

        - to detect hand sanitizer/face mask/thermometer

    - draw.py

      - 画标注框，helloworld级别

    - gps.py

      - the demo code for our gps system
      - it is seperated out from the main.py because it is hardware-dependant code

    - main.py

      - 主线程
      - 流程参考了别人的工作：
        - ![program flowchart](https://raw.githubusercontent.com/Wendy-Wu/imagebed/main/img/program flowchart.png)

    - oak_blind.py

      - 识别车道线（斑马线为负样本？)，跑的是crosswalkPipeline.run()

    - oakd_all.py

      - 识别全类别，但跑的是crosswalkPipeline.run()

    - oakd_crosswalk.py

      - 识别斑马线（车道线是负样本？），跑的是crosswalkPipeline.run()

    - oakd_navigation.py

      - 别人的工作，label包括了很多实体目标，比如车，鸟，人。跑的是navPipeline.run()

    - oakd_ppes.py

      - 别人的工作，检测ppe，利用语音输入指令。

        ```python
        speech = SpeechRecognizer()
        speech.start()
        ```

      - 跑的是如下pipeline：

      - ```python
        ppesPipeline.run(speech)
        speech.listen = False
        speech.end = True     
        speech.join()  
        ```

    - oakd_ppes_no_audio.py

      - 别人的工作，没有语音输入的情况。

    - oakd_segmentation.py

      - 别人的语义分割道路的工作

    - oakd_traffic_light.py

      - 红绿灯识别的线程。

    - OUTPUT.py

      - 输出目标框
      - 设置视频流路径、模型路径
      - 创建pipeline
      - 设置模型、yolo参数比如类别数目、IoU阈值、anchor初始位置
      - 连接到设备并启动Pipeline
      - 发送帧到设备
      - 从设备获取检测结果
      - 显示和保存处理后的帧

    - README.md

      - 别人工作里的工程说明文件。

        OpenCV-AI-Competition-UTAR4Vision

        We are team **UTAR4Vision**!
        This is the github repository for our team project - **Visually Impaired Assistance in COVID-19 Pandemic Outbreak**.

      - 有关oak-d，pipeline的说明

      - 对每个oak_...py的文件介绍

    - speaktest.py

      - 测试语音功能

    - task_utils.py

      - ##### Speech Recognition

        - an OOP object for speech recognition and voice command
        - designed for multithreading

      - ##### Navigator

        - contains the functions for obstacle avoidance, social distancing

    - test.py

      - 测试创建pipeline，连接设备、运行pipeline

    - testAll.py

      - 测试全类别检测
      - 代码构建与OUTPUT.py相似

    - testvedio.py

      - main函数路径包括了输入是视频流还是摄像头这两种选择
      - 根据输入，具体创建pipeline
      - 根据视频流，创建model neural network
      - 并且运行pipeline和网络，检测目标

    - v5_oakd_traffic_light.py

      - 别人工作里的红绿灯检测

    - vedio.py

      - 视频的读取显示，helloworld级别

    - yolov4_crosswalk.py

      - 别人工作里的斑马线检测

    - yolov8_oak.py

      - 暂时没看出来是v8